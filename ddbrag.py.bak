import duckdb
import pandas as pd
from sentence_transformers import SentenceTransformer

# Set DataFrame
def set_dataframe():
    # Load dataset directly from huggingface
    dataframe_name = input(
        "Enter the name of the dataframe (or press Enter for default): ")
    if not dataframe_name:
        print("Loading default dataset")
        duckdb.sql(
            "SELECT * FROM 'hf://datasets/airesearch/WangchanX-Legal-ThaiCCL-RAG/data/*.parquet';").df()
        return df
    else:
        # If user provides a custom dataset path
        df = duckdb.sql(f"SELECT * FROM '{dataframe_name';").df()
        return df

def set_model():
    # Load the embedding model
    print("\nAvailable Models:")

    model_name = input("Enter the name of the embedding model from SentenceTransformer: ")
    if not model_name:
        SentenceTransformer("jinaai/jina-embeddings-v3",
                            trust_remote_code=True, device='cuda:0')
    print(f"Loading model '{model_name}'...")
    model = SentenceTransformer(
        model_name, trust_remote_code=True, device='cuda:0')
    return model

# Function to encode text with error handling


def encode_text(text, model, idx=None):
    try:
        print(f"Processing row {idx}: {text[:100]}...")  # Show first 100 chars
        return model.encode(text)
    except Exception as e:
        print(f"Error in row {idx}: '{str(e)}'")
        return None


def pickle_df(dataframe):
    # Apply the encoding function to the 'question' column
    print("Encoding all questions in the dataframe...")
    dataframe['embeddings'] = dataframe['question'].apply(
        lambda x: encode_text(x, dataframe[dataframe['question'] == x].index[0]))

    # Save the dataframe
    print("Saving dataframe to pickle file...")
    dataframe.to_pickle('dataframe.pkl')

    # Load the dataframe
    df = pd.read_pickle('dataframe.pkl')
    return df

# Performing Similarity Search Function


def similarity_search(
    query: str,
    model: str,
    k: int = 5,
    dataset_name: str = "db",  # Name of the variable dataframe above
    embedding_column: str = "embeddings",
):
    print(f"Encoding query vector '{query}'")
    query_vector = model.encode(query)
    print(f"Query vector '{query_vector}' created!  Creating embedding_dim...")
    embedding_dim = model.get_sentence_embedding_dimension()

    sql = f"""
        SELECT
            *,
            array_cosine_distance(
                {embedding_column}::float[{embedding_dim}],
                {query_vector.tolist()}::float[{embedding_dim}]
            ) as distance
        FROM '{dataset_name}'
        ORDER BY distance
        LIMIT {k}
    """
    return duckdb.sql(sql).to_df()


def main():
    print("Setting model...")
    model = set_model()
    print(f"Model set to {model}")

    # Load or create the dataframe with embeddings
    try:
        print("nAttempting to load existing pickled dataframe...")
        df = pd.read_pickle('dataframe.pkl')
        print("Dataframe loaded from pickle file!")
    except FileNotFoundError:
        print("No pickle file found.  Loading dataset and creating embedding")
        dataframe = set_dataframe()
        df = pickle_df(dataframe, model)

    # Sample query
    print("Setting query to 'ถ้าเราขุดของมีค่าได้ เราต้องส่งมอบให้ใคร'")
    query = "ถ้าเราขุดของมีค่าได้ เราต้องส่งมอบให้ใคร"
    print("Query set!  Performing similarity search on query...")
    # Register the dataframe with DuckDB so it can be queried
    duckdb.register('db', df)
    results = similarity_search(query_vec, model)
    # Display results
    print("\n=== Search Results ===")
    print(results[['question', 'distance']])


if __name__ == "__main__":
    main()
